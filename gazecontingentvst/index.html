<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript" src="http://code.jquery.com/jquery-2.1.3.min.js"></script>

<script src="before-after/before-after.min.js"></script>
<link type="text/css" href="before-after/before-after.min.css" rel="stylesheet">

<script>
function CopyToClipboard(id)
{
var r = document.createRange();
r.selectNode(document.getElementById(id));
window.getSelection().removeAllRanges();
window.getSelection().addRange(r);
document.execCommand('copy');
window.getSelection().removeAllRanges();
}
</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1920px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
    
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
    
    .pointable {
       cursor: pointer;
    }
    
    .vid_background {
        background: url('resources/prototype_closed.jpg') no-repeat top left transparent;
         width: 1024px; /* Adjust TV image width */
        height: 576px; /* Adjust TV image height */
        position: relative;
    }
    
    .testtable
    { 
        margin-left: auto;
        margin-right: auto;
    }
</style>

<html>
<head>
	<title>Video See-Through Mixed Reality with Focus Cues</title>
</head>

<body>
	<br>
	<center>
        <span style="font-size:36px">Video See-Through Mixed Reality with Focus Cues</span> </br>
         <span style="font-size:24px; color:#878787">Best Journal Paper at IEEE VR 2022</span></center></br></br>
		<table align=center width=1024px>
			<table align=center width=1000px>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px">Christoph Ebner</span></br>
                            <span style="font-size:14px">Graz University of Technology</span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px">Shohei Mori</span></br>
                            <span style="font-size:14px">Graz University of Technology</span>
						</center>
					</td>
                    <td align=center width=100px>
						<center>
							<span style="font-size:24px">Peter Mohr</span></br>
                            <span style="font-size:14px">Graz University of Technology</span>
						</center>
					</td>
                    <td align=center width=100px>
						<center>
							<span style="font-size:24px">Yifan Peng</span></br>
                            <span style="font-size:14px">Stanford University</span>
						</center>
					</td>
				</tr>
			</table></br>
            <table align=center width=1024px>
			<table align=center width=800px>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px">Dieter Schmalstieg</span></br>
                            <span style="font-size:14px">Graz University of Technology</span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px">Gordon Wetzstein</span></br>
                            <span style="font-size:14px">Stanford University</span>
						</center>
					</td>
                    <td align=center width=100px>
						<center>
							<span style="font-size:24px">Denis Kalkofen</span></br>
                            <span style="font-size:14px">Graz University of Technology</span>
						</center>
					</td>
				</tr>
			</table></br>
		</table>
	</center>

	<center>
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
						<img class="round" style="width:1100px" src="./resources/Teaser.jpg"/>
					</center>
				</td>
			</tr>
		</table>
	</center></br></br>

			<table align=center width=800px>
				<tr>
					<td align=center width=64px>
						<center>
                            <a href="resources/paper.pdf">
                            <image src="resources/bootstrap_icons/file-earmark-text.svg" height="100px">
                                <h4><strong>Paper</strong></h4>
                            </a>
						</center>
					</td>
                    <td align=center width=64px>
						<center>
                            <a href="https://www.youtube.com/watch?v=uAQVrfnlOwo">
                            <image src="resources/bootstrap_icons/camera-reels.svg" height="100px">
                                <h4><strong>Video</strong></h4>
                            </a>
						</center>
					</td>
					<td align=center width=64px>
						<center>
                            <a href="https://www.youtube.com/watch?v=h9rMn6J2zd0">
                            <image src="resources/bootstrap_icons/youtube.svg" height="100px">
                                <h4><strong>Talk</strong></h4>
                            </a>
						</center>
					</td>
                    <td align=center width=64px>
						<center>
                            <a href="resources/Slides.pdf">
                            <image src="resources/bootstrap_icons/file-earmark-slides.svg" height="100px">
                                <h4><strong>Slides</strong></h4>
                            </a>
						</center>
					</td>
				</tr>
			</table>

	<hr>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				This work introduces the first approach to video see-through mixed reality with full support for focus cues. By combining the flexibility to adjust the focal distance found in varifocal designs with the robustness to eye-tracking error found in multifocal designs, our novel display architecture reliably delivers focus cues over a large workspace. In particular, we introduce gaze-contingent layered displays and mixed reality focal stacks, an efficient representation of mixed reality content that lends itself to fast processing for driving layered displays in real-time. We thoroughly evaluate this approach by building a complete end-to-end pipeline for capture, render, and display of focus cues in video see-through displays that uses only off-the-shelf hardware and compute components.
			</td>
		</tr>
	</table><br>

	<hr>
	<center><h1>Prototype</h1></center>
    <center>
        <script>
            function ChangeAndPlayVideo()
            {
                var video = document.getElementById('prototype_video');
                var src_attrib = video.getAttribute('src');
                var mode = src_attrib == "resources/prototype_notes.mp4" && src_attrib != null;
                if (mode)
                {
                    video.setAttribute('src', 'resources/prototype_rev.mp4');
                   
                }
                else
                {
                   video.setAttribute('src', 'resources/prototype_notes.mp4');
                   
                }
                video.play();
            }
        </script>
        
        <div id="video_background" class="vid_background">
            <video id="prototype_video" class="pointable" width="1024" muted preload onclick="ChangeAndPlayVideo()">
                <source src="resources/prototype_notes.mp4" type="video/mp4">
                <p>Your user agent does not support the HTML5 Video element.</p>

            </video>
        </div>
        
        <script>
            function delay(time) 
            {
              return new Promise(resolve => setTimeout(resolve, time));
            }
            
            const video = document.getElementById('prototype_video');
            video.onplay = (event) => 
            {
                delay(500).then(() => 
                {
                    var bg = document.getElementById('video_background');
                                    var video = document.getElementById('prototype_video');
                    var src_attrib = video.getAttribute('src');
                    var mode = src_attrib == "resources/prototype_notes.mp4" && src_attrib != null;
                    if (mode)
                    {
                        bg.style.backgroundImage = "url('resources/prototype_open.jpg')";
                    }
                    else
                    {
                        bg.style.backgroundImage = "url('resources/prototype_closed.jpg')";
                    }
                })
            };
        </script>
        <br><table align=center width=1024px>
		<tr>
			<td>
                Our video see-through display prototype can be built with off-the-shelf components in a relatively small form factor.
                Click on the prototpye to explode the view. 
                The display consists of two LCDs per eye which are combined by a beam splitter. 
                Focus tunable lenses allow to shift the virtual image of the LCDs to the vergence distance of the user,
                which is measured by a binocular eye tracker. For capturing, we use industrial cameras. The focus distance of
                the cameras is controlled by focus tunable lenses.
                Additionally, we include a 6DoF tracker, and a hand tracker in our prototype.
			</td>
		</tr>
	</table><br>
    </center>
	<hr>
        <script>
function ChangeFocusImages(augms_are_on)
    {
        var butt_rear = document.getElementById("butt_img_rear");
        var butt_front = document.getElementById("butt_img_front");
        
        var farm_rear = document.getElementById("farm_img_rear");
        var farm_front = document.getElementById("farm_img_front");
        
        console.debug(augms_are_on);
        if (augms_are_on)
        {
            butt_rear.setAttribute('src', "resources/ButtBackFocus.jpg");
            butt_front.setAttribute('src', "resources/ButtFrontFocus.jpg");
            farm_rear.setAttribute('src', "resources/FarmRearFocus.jpg");
            farm_front.setAttribute('src', "resources/FarmFrontFocus.jpg");
        }
        else
        {
            butt_rear.setAttribute('src', "resources/ButtBackFocus_no_aug.jpg");
            butt_front.setAttribute('src', "resources/ButtFrontFocus_no_aug.jpg");
            farm_rear.setAttribute('src', "resources/FarmRearFocus_no_aug.jpg");
            farm_front.setAttribute('src', "resources/FarmFrontFocus_no_aug.jpg");
        }
    }
</script>
	<center><h1>Example Results</h1>
			<table align="center" style="width:1024px;margin: 0px auto;">
					<td>
                            <div class="ba-slidera">
                                <img src="resources/ButtBackFocus.jpg" id="butt_img_rear">
                                <div class="resize">
                                    <img src="resources/ButtFrontFocus.jpg" id="butt_img_front">
                                </div>
                                <span class="handle"></span>
                            </div>
                            <script type="text/javascript">
                                $('.ba-slidera').beforeAfter('507');
                            </script>
					</td>
					<td>
                            <div class="ba-sliderb">
                                <img src="resources/FarmRearFocus.jpg" id="farm_img_rear">
                                <div class="resize">
                                    <img src="resources/FarmFrontFocus.jpg" id="farm_img_front">
                                </div>
                                <span class="handle"></span>
                            </div>
                            <script type="text/javascript">
                                $('.ba-sliderb').beforeAfter('507');
                            </script>
					</td>
			</table>
        <label><input type='checkbox' onclick='ChangeFocusImages(this.checked);' checked>Show augmentations</label>

        </center>
        <br>
        <center><table align=center width=1024px>
		<tr>
			<td>
                These example results show simulations of two scenes with user front and back focus. Our software pipeline allows us to augment a captured focal stack with
                a rendered focal stack. Drag the slider to compare between front and back focus. Use the button on the bottom
                to toggle between viewing the mixed focal stack and the captured focal stack.
			</td>
		</tr>
	</table> </center><br>
	<hr>
    <center><h1>Comparison to Single Layer Varifocal</h1></center>
    
    <table align="center" style="width:1024px;margin: 0px auto;">
    <td>
            <div class="ba-sliderd">
                <img src="resources/comp/vari_et_0.4.jpg" id="comp_vari">
                <div class="resize">
                    <img src="resources/comp/2l_et0.4.jpg" id="comp_layered">
                </div>
                <span class="handle"></span>
            </div>
            <script type="text/javascript">
                $('.ba-sliderd').beforeAfter('1024');
            </script>
    </td>
        <script>
function ChangeCompImages(slider_value)
    {
        var val = document.getElementById("slider_value_comp");
        val.textContent = slider_value;
        
        var vari_img = document.getElementById("comp_vari");
        var layered_img = document.getElementById("comp_layered");
        
        layered_img.setAttribute('src', "resources/comp/2l_et" + slider_value + ".jpg");
        vari_img.setAttribute('src', "resources/comp/vari_et_" + slider_value + ".jpg");
    }
</script>
</table><br>
    <center>
    <p>Eye Tracking Error
    <input id="input" type="range" min="0" value="0.4" max="0.6" step="0.1" oninput="ChangeCompImages(this.value)" style="width: 512px;">
    <span id="slider_value_comp">0.4</span>
        Diopter
        </p>
    </center>
<table align=center width=1024px>
		<tr>
			<td>
                The dual layer varifocal setup allows our prototype to be tolerant against eye tracking errors. The accuracy of current generation eye trackers is 
                about 0.5° - 1°, which results in vergence measurement offsets of about 0.3D - 0.6D (see our paper for details).
                Use the slider on the bottom to adjust the eye tracking error and drag the image slider to compare our setup against a conventional
                varifocal display.
			</td>
		</tr>
	</table>
    <hr>
	<center><h1>Citation<input type="image" src="resources/bootstrap_icons/files.svg" height="20px" onclick="CopyToClipboard('cite_bib')"></h1></center>
			<table align=center width=1000px>
				<tr>
					<td align=left width=100px>
						<center>
                            <p id="cite_bib" style="font-size:12px;  white-space: pre-wrap;">@article{ebner2022vst,
  author={Ebner, Christoph and Mori, Shohei and Mohr, Peter and Peng, Yifan and Schmalstieg, Dieter and Wetzstein, Gordon and Kalkofen, Denis},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Video See-Through Mixed Reality with Focus Cues}, 
  year={2022},
  volume={},
  number={},
  pages={1-1}}
</p>
						</center>
					</td>
			</table></br>

	<hr>
	<br>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>

