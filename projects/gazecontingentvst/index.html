<!doctype html>
<html lang="en">
<head>
	<title>Video See-Through Mixed Reality with Focus Cues</title>
	
	<!-- Required meta tags -->
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, minimum-scale=1.0">
	<meta name="description" content="Video See-Through Mixed Reality with Focus Cues is a TVCG Paper.">
	<meta name="keywords" content="best journal paper, gaze contingent, mixed reality, augmented reality, immersive technology lab, tugraz, tvcg, ieee vr">
	<meta name="author" content="Immersive Technology Lab, TUGraz">

	<!-- Bootstrap v5.1.3 CSS and JS (https://getbootstrap.com/) -->
	<link href="../../common/bootstrap-5.1.3-dist/css/bootstrap.min.css" rel="stylesheet">
	<script src="../../common/bootstrap-5.1.3-dist/js/bootstrap.bundle.min.js"></script>

	<!-- definitive-image-comparison-slider by Abel Cabeza RomÃ¡n (https://github.com/abelcabezaroman/definitive-image-comparison-slider) -->
	<link rel="stylesheet" href="../../common/definitive-image-comparison-slider/dics.css">
	<script src="../../common/definitive-image-comparison-slider/dics.js"></script>
	<script src="assets/js/BeforeAfter.js"></script> <!-- Change this to modify the effect -->

	<!-- custom fonts -->
	<link rel="stylesheet" href="../../common/fonts/latofonts.css">
	<link rel="stylesheet" href="css/fonts.css">
</head>

<body>
<!-- Begin page content -->
<main>
	<section class="hero-banner bg-dark bg-opacity-10 pt-1 pb-4">
	<div class="container text-center">
		<!-- Title and a note -->
		<h1 class="mt-4">Video See-Through Mixed Reality with Focus Cues</h1>
		<h4 class="text-black-50">Transactions on Visualization and Computer Graphics (TVCG)</h4>
		<h5 class="text-black-50"><i><strong>Best Journal Paper</strong> at IEEE VR 2022</i></h5>
		<h5 class="text-black-50"><i>TVCG Session on VR (<strong>Invited Talk</strong>) at SIGGRAPH 2022</i></h5>

		<!-- Author info. Tips: https://getbootstrap.com/docs/5.0/layout/grid/ -->
		<div class="mt-4">
			<div class="row">
				<div class="col">
					<a class="lead link-dark text-decoration-none">Christoph Ebner</a><br>
					<small>Graz University of Technology</small>
				</div>
				<div class="col">
					<a class="lead link-dark text-decoration-none" href="https://mugichoko445.bitbucket.io/" target="_blank">Shohei Mori</a><br>
					<small>Graz University of Technology</small>
				</div>
				<div class="col">
					<a class="lead link-dark text-decoration-none">Peter Mohr</a><br>
					<small>Graz University of Technology</small>
				</div>
				<div class="col">
					<a class="lead link-dark text-decoration-none">Yifan (Evan) Peng</a><br>
					<small>Stanford University</small>
				</div>
			</div>
			<div class="row">
				<div class="col-1">
				</div>
				<div class="col">
					<a class="lead link-dark text-decoration-none">Dieter Schmalstieg</a><br>
					<small>Graz University of Technology</small>
				</div>
				<div class="col">
					<a class="lead link-dark text-decoration-none" href="https://mugichoko445.bitbucket.io/" target="_blank">Gordon Wetzstein</a><br>
					<small>Stanford University</small>
				</div>
				<div class="col">
					<a class="lead link-dark text-decoration-none">Denis Kalkofen</a><br>
					<small>Graz University of Technology</small>
				</div>
				<div class="col-1">
				</div>
			</div>
		</div>
	</div>
	</section>

	<section class="hero-banner bg-white shadow-lg shadow pt-4 pb-4">
	<div class="container text-center">
		<!-- Teaser image -->
		<div class="mb-2">
			<div class="row">
			<img src="assets/img/teaser.jpg" class="img-fluid" alt="Teaser image">
			</div>
		</div>


		<!-- Content icons -->
		<!-- Bootstrap icons v.1.8.1 (https://icons.getbootstrap.com/) -->
		<div class="mt-5">
			<div class="row mb-3">
				<div class="col">
					<figure class="figure"><a class="text-decoration-none" href="https://doi.org/10.1109/TVCG.2022.3150504" target="_blank">
						<img src="../../common/icons-1.8.1/link-45deg.svg" alt="Link to IEEE Xplore" width="70" height="70" title="IEEE Xplore">
						<figcaption class="figure-caption mt-1"><b>Xplore</b></figcaption>
					</a></figure>
				</div>
				<div class="col">
					<figure class="figure"><a class="text-decoration-none" href="assets/vr22_ebner_paper.pdf" target="_blank">
						<img src="../../common/icons-1.8.1/file-earmark-text.svg" alt="Link to Author Preprint" width="70" height="70" title="Author Preprint">
						<figcaption class="figure-caption mt-1"><b>Preprint</b></figcaption>
					</a></figure>
				</div>
				<div class="col">
					<figure class="figure"><a class="text-decoration-none" href="https://www.youtube.com/watch?v=uAQVrfnlOwo" target="_blank">
						<img src="../../common/icons-1.8.1/file-earmark-play-fill.svg" alt="Link to Technical Video" width="70" height="70" title="Technical Video">
						<figcaption class="figure-caption mt-1"><b>Video</b></figcaption>
					</a></figure>
				</div>
				<div class="col">
					<figure class="figure"><a class="text-decoration-none" href="https://www.youtube.com/watch?v=h9rMn6J2zd0" target="_blank">
						<img src="../../common/icons-1.8.1/mic.svg" alt="Link to IEEE VR Talk" width="70" height="70" title="IEEE VR Talk">
						<figcaption class="figure-caption mt-1"><b>Talk</b></figcaption>
					</a></figure>
				</div>
				<div class="col">
					<figure class="figure"><a class="text-decoration-none" href="assets/vr22_ebner_slides.pdf" target="_blank">
						<img src="../../common/icons-1.8.1/file-earmark-slides.svg" alt="Link to Slides" width="70" height="70" title="Slides">
						<figcaption class="figure-caption mt-1"><b>Slides</b></figcaption>
					</a></figure>
				</div>
			</div>
		</div>
		

		<!-- custom h line -->
		<hr style="margin: 0 25% 1rem 25%;">
		

		<!-- Abstract -->
		<h3 class="my-5">Abstract</h3>
		<p class="mb-5 text-start">
			This work introduces the first approach to video see-through mixed reality with full support for focus cues. By combining the flexibility to adjust the focal distance found in varifocal designs with the robustness to eye-tracking error found in multifocal designs, our novel display architecture reliably delivers focus cues over a large workspace. In particular, we introduce gaze-contingent layered displays and mixed reality focal stacks, an efficient representation of mixed reality content that lends itself to fast processing for driving layered displays in real-time. We thoroughly evaluate this approach by building a complete end-to-end pipeline for capture, render, and display of focus cues in video see-through displays that uses only off-the-shelf hardware and compute components.
		</p>
		

		<!-- custom h line -->
		<hr style="margin: 0 25% 1em 25%;">
		

		<!-- Results -->
		<h3 class="my-5">Prototype</h3>
		<script>
		function ChangeAndPlayVideo()
		{
			var video_notes = document.getElementById('prototype_video_notes');
			var video_rev = document.getElementById('prototype_video_rev');

			if (video_notes.style.display == "initial")
			{
				video_notes.style.display = "inline";
				video_notes.play();
			}
			else if (video_notes.style.display == "inline")
			{
				video_notes.style.display = "none";
				video_notes.pause();
				video_notes.currentTime = 0;
				video_notes.load();

				video_rev.style.display = "inline";
				video_rev.play();
			}
			else if (video_notes.style.display == "none")
			{
				video_rev.style.display = "none";
				video_rev.pause();
				video_rev.currentTime = 0;
				video_rev.load();

				video_notes.style.display = "inline";
				video_notes.play();
			}
		}
		</script>

		<div class="row" id="video_background">
			<video id="prototype_video_notes" onclick="ChangeAndPlayVideo()" style="display: initial;">
				<source src="assets/img/prototype_notes.mp4" type="video/mp4">
				<p>Your user agent does not support the HTML5 Video element.</p>
			</video>
			<video id="prototype_video_rev" onclick="ChangeAndPlayVideo()" style="display: none;">
				<source src="assets/img/prototype_rev.mp4" type="video/mp4">
				<p>Your user agent does not support the HTML5 Video element.</p>
			</video>
		</div>


		<p class="my-5 text-start">
			Our video see-through display prototype can be built with off-the-shelf components in a relatively small form factor. <strong>Click on the prototype to explode the view</strong>. The display consists of two LCDs per eye which are combined by a beam splitter. Focus tunable lenses allow to shift the virtual image of the LCDs to the vergence distance of the user, which is measured by a binocular eye tracker. For capturing, we use industrial cameras. The focus distance of the cameras is controlled by focus tunable lenses. Additionally, we include a 6DoF tracker, and a hand tracker in our prototype.
		</p>


		<!-- custom h line -->
		<hr style="margin: 5em 25% 1em 25%;">
		

		<!-- Example Results -->
		<h3 class="my-5">Example Results</h3>

		<script>
		function ChangeFocusImages(augms_are_on)
		{
			var butt_rear = document.getElementById("butt_img_rear");
			var butt_front = document.getElementById("butt_img_front");

			var farm_rear = document.getElementById("farm_img_rear");
			var farm_front = document.getElementById("farm_img_front");

			console.debug(augms_are_on);
			if (augms_are_on)
			{
				butt_rear.setAttribute('src', "assets/img/butt_rearfocus.jpg");
				butt_front.setAttribute('src', "assets/img/butt_frontfocus.jpg");
				farm_rear.setAttribute('src', "assets/img/farm_rearfocus.jpg");
				farm_front.setAttribute('src', "assets/img/farm_frontfocus.jpg");
			}
			else
			{
				butt_rear.setAttribute('src', "assets/img/butt_rearfocus_no_aug.jpg");
				butt_front.setAttribute('src', "assets/img/butt_frontfocus_no_aug.jpg");
				farm_rear.setAttribute('src', "assets/img/farm_rearfocus_no_aug.jpg");
				farm_front.setAttribute('src', "assets/img/farm_frontfocus_no_aug.jpg");
			}
		}
		</script>

		<div class="row my">
			<div class="col-lg-6 mb-1">
				<div class="b-dics">
					<img class="img-fluid" src="assets/img/butt_frontfocus.jpg" id="butt_img_front">
					<img class="img-fluid" src="assets/img/butt_rearfocus.jpg" id="butt_img_rear">
				</div>
			</div>
			<div class="col-lg-6 mb-3">
				<div class="b-dics">
					<img class="img-fluid" src="assets/img/farm_frontfocus.jpg" id="farm_img_front">
					<img class="img-fluid" src="assets/img/farm_rearfocus.jpg" id="farm_img_rear">
				</div>
			</div>
		</div>

		<label><input type='checkbox' onclick='ChangeFocusImages(this.checked);' checked> Show Augmentations</label>


		<p class="mt-2 text-start">
			These example results show simulations of two scenes with user front and back focus. Our software pipeline allows us to augment a captured focal stack with a rendered focal stack. Drag the slider to compare between front and back focus. Use the button on the bottom to toggle between viewing the mixed focal stack and the captured focal stack.
		</p>


		<!-- custom h line -->
		<hr style="margin: 5em 25% 1em 25%;">


		<!-- Results -->
		<h3 class="my-5">Comparison to Single Layer Varifocal</h3>

		<script>
		function ChangeCompImages(slider_value)
		{
			var val = document.getElementById("slider_value_comp");
			val.textContent = slider_value;

			var vari_img = document.getElementById("comp_vari");
			var layered_img = document.getElementById("comp_layered");

			layered_img.setAttribute('src', "assets/img/comp/2l_et" + slider_value + ".jpg");
			vari_img.setAttribute('src', "assets/img/comp/vari_et_" + slider_value + ".jpg");
		}
		</script>

		<div class="row my">
			<div class="col mb-1">
				<div class="b-dics">
					<img class="img-fluid" src="assets/img/comp/2l_et0.4.jpg" id="comp_layered">
					<img class="img-fluid" src="assets/img/comp/vari_et_0.4.jpg" id="comp_vari">
				</div>
			</div>
		</div>

		<p class="my-2">Eye Tracking Error
		<input id="input" type="range" min="0" value="0.4" max="0.6" step="0.1" oninput="ChangeCompImages(this.value)">
		<span id="slider_value_comp">0.4</span>
		Diopter
		</p>

		<p class="mt-2 text-start">
			The dual layer varifocal setup allows our prototype to be tolerant against eye tracking errors. The accuracy of current generation eye trackers is about 0.5Â° - 1Â°, which results in vergence measurement offsets of about 0.3D - 0.6D (see our paper for details). Use the slider on the bottom to adjust the eye tracking error and drag the image slider to compare our setup against a conventional varifocal display.
		</p>


		<!-- custom h line -->
		<hr style="margin: 5em 25% 1em 25%;">


		<!-- Citation -->
		<h3 class="my-5">Citation 
			<button type="button" class="btn btn-outline-secondary btn-sm" data-bs-container="body" data-bs-toggle="popover" data-bs-placement="top" data-bs-content="Copied!" onclick="CopyToClipboard('bib')">
			Copy
			</button>
		</h3>
		<div class="col text-start bg-dark bg-opacity-10 rounded-3 px-3">
		<pre><code id="bib">
@article{ebner2022vst,
	author={Ebner, Christoph and Mori, Shohei and Mohr, Peter and Peng, Yifan and Schmalstieg, Dieter and Wetzstein, Gordon and Kalkofen, Denis},
	journal={IEEE Transactions on Visualization and Computer Graphics}, 
	title={Video See-Through Mixed Reality with Focus Cues}, 
	year={2022},
	volume={28},
	number={5},
	pages={2256-2266}
}
		</code></pre>
		</div>

		<script src="../../common/copy-to-clipboard-js/CopyToClipboard.js"></script>
		<script src="../../common/copy-to-clipboard-js/Popover.js"></script>
	</div>
	</section>


	<section class="hero-banner bg-dark bg-opacity-10 pt-1 pb-4">
	<div class="container">
		<div class="row mt-5">
			<div class="col">
				<h3>Links</h3>
				<ul>
					<li><a class="link-dark text-decoration-none" href="https://immersive-technology-lab.github.io/" target="_blank">Immersive Technology Lab (TUGraz)</a></li>
				</ul>
			</div>
		</div>
	</div>
	</section>

</main>
</body>
</html>